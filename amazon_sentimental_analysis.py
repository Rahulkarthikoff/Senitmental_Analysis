# -*- coding: utf-8 -*-
"""Amazon_Sentimental_Analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18HXRDuGTIo_RFVtRFkDqQlCMzDH0ylC0
"""



from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

plt.style.use('ggplot')

import nltk
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')
nltk.download('maxent_ne_chunker')
nltk.download('words')
nltk.download('vader_lexicon')

#READING DATA
df = pd.read_csv('/content/drive/MyDrive/Online Projects/Reviews.csv')

df.head()

df.shape

df = df.head(500)
df

ax = df['Score'].value_counts().sort_index().plot(kind='bar',title = "Count of Review by Stars",figsize=(10,5))

ax.set_xlabel('Review Stars')
plt.show()

example = df['Text'][50]
print(example)

tokens = nltk.word_tokenize(example)
print(tokens[:10])

tagged = nltk.pos_tag(tokens)
print(tagged[:10])

entities = nltk.chunk.ne_chunk(tagged)
entities.pprint()

from nltk.sentiment import SentimentIntensityAnalyzer
from tqdm.notebook import tqdm

sia = SentimentIntensityAnalyzer()

sia.polarity_scores("I am so Happy!")

sia.polarity_scores("This is the worst thing ever!")

sia.polarity_scores(example)

#RUN THE POLARITY SCORE FOR THE ENTIRE DATASET
res = {}
for i,row in tqdm(df.iterrows(),total = len(df)):
  text = row['Text']
  myid = row['Id']
  res[myid] = sia.polarity_scores(text)

print(res)

vaders = pd.DataFrame(res).T
vaders = vaders.reset_index().rename(columns= {'index':'Id'})
print(vaders)
vaders = vaders.merge(df,how = 'left')

#Now we have sentiment score and metadata
vaders.head()

#Plot VADERS Results
ax = sns.barplot(data = vaders, x = 'Score', y='compound')
ax.set_title("Compound Score by Amazon Stars review")
plt.show()

fig,axs = plt.subplots(1,3,figsize=(12,3))
sns.barplot(data=vaders,x='Score',y='pos',ax = axs[0])
sns.barplot(data=vaders,x='Score',y='neu',ax = axs[1])
sns.barplot(data=vaders,x='Score',y='neg',ax = axs[2])
axs[0].set_title("Positive")
axs[1].set_title("Neutral")
axs[2].set_title("Negative")
plt.tight_layout()
plt.show()

from transformers import AutoTokenizer
from transformers import AutoModelForSequenceClassification
from scipy.special import softmax

MODEL = f"cardiffnlp/twitter-roberta-base-sentiment"
tokenizer = AutoTokenizer.from_pretrained(MODEL)
model   =  AutoModelForSequenceClassification.from_pretrained(MODEL)

#VADER results on example
print(example)
sia.polarity_scores(example)

#RUN FOR ROBERTA MODEL
encoder_text = tokenizer(example,return_tensors='pt')
output = model(**encoder_text)
scores = output[0][0].detach().numpy()
scores = softmax(scores)
scores_dict = {   'roberta_neg':scores[0],
               'roberta_neu':scores[1],
                  'roberta_pos':scores[2]}
print(scores_dict)

def polarity_scores_roberta(example):
  encoder_text = tokenizer(example,return_tensors='pt')
  output = model(**encoder_text)
  scores = output[0][0].detach().numpy()
  scores = softmax(scores)
  scores_dict = {   'roberta_neg':scores[0],
               'roberta_neu':scores[1],
                  'roberta_pos':scores[2]}

  return scores_dict

res = {}
for i,row in tqdm(df.iterrows(),total = len(df)):
  try:
    text = row['Text']
    myid = row['Id']
    vader_result = sia.polarity_scores(text)
    vader_result_rename = {}
    for key,value in vader_result.items():
      vader_result_rename[f"vader_{key}"] = value

    roberta_result = polarity_scores_roberta(text)
    both = {**vader_result_rename,**roberta_result}
    res[myid]= both
  except RuntimeError:
      print(f'Broke for id {myid}')

results_df = pd.DataFrame(res).T
results_df = results_df.reset_index().rename(columns= {'index':'Id'})
results_df = results_df.merge(df,how = 'left')

results_df.head()

results_df.columns

#Compare Scores Between Models
sns.pairplot(data = results_df,
            vars = ['vader_neg', 'vader_neu', 'vader_pos',
                    'roberta_neg', 'roberta_neu', 'roberta_pos'],
            hue = 'Score',
            palette='tab10')
plt.show()

#positive review with 1-Star
results_df.query('Score == 1').sort_values('roberta_pos',ascending=False)['Text'].values[0]

#positive review with 1-Star

results_df.query('Score == 1').sort_values('vader_pos',ascending=False)['Text'].values[0]

#negative review with 5-Star view
results_df.query('Score == 5').sort_values('roberta_neg',ascending=False)['Text'].values[0]

#negative review with 5-Star view
results_df.query('Score == 5').sort_values('vader_neg',ascending=False)['Text'].values[0]

from transformers import pipeline
sent_pipeline = pipeline("sentiment-analysis")

sent_pipeline('I Love Sentiment Analysis')

sent_pipeline('Make sure  to like and subscribe')

sent_pipeline('booo........')

#THE END!!!!